{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSUWcRP+25UaexBzl2XXIt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IngerMasha/week12/blob/main/Basic_of_Webscrapping_Exercises_XP_Gold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EgbSC_eSiXi",
        "outputId": "96a0dde2-d38e-4272-fe13-2a24f5a21887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The page at https://www.example.com is available.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "def check_page_availability(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            print(f\"The page at {url} is available.\")\n",
        "        else:\n",
        "            print(f\"The page at {url} returned status code {response.status_code}.\")\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "check_page_availability(\"https://www.example.com\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def count_datasets():\n",
        "    url = \"https://www.data.gov\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    dataset_count_element = soup.find(\"span\", class_=\"dataset-count\")\n",
        "    if dataset_count_element:\n",
        "        print(f\"Number of datasets listed: {dataset_count_element.text.strip()}\")\n",
        "    else:\n",
        "        print(\"Couldn't find dataset count element.\")\n",
        "count_datasets()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VHYT8eISvYY",
        "outputId": "29c53096-31e7-46a2-c235-9708899e74e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Couldn't find the dataset elements.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def latest_dataset():\n",
        "    url = \"https://www.data.gov\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    latest_dataset_element = soup.find(\"div\", class_=\"latest-dataset\")\n",
        "    if latest_dataset_element:\n",
        "        dataset_name = latest_dataset_element.find(\"a\").text.strip()\n",
        "        print(f\"Most recently added dataset: {dataset_name}\")\n",
        "    else:\n",
        "        print(\"Couldn't find the latest dataset element.\")\n",
        "\n",
        "latest_dataset()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5LgJDMXS1FX",
        "outputId": "d5b0ebca-efb4-4210-a193-a92ba7b819f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Couldn't find the latest dataset element.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def extract_h1_tag():\n",
        "    url = \"https://www.example.com\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    h1_tag = soup.find(\"h1\")\n",
        "    if h1_tag:\n",
        "        print(f\"h1 tag content: {h1_tag.text.strip()}\")\n",
        "    else:\n",
        "        print(\"Couldn't find h1 tag.\")\n",
        "extract_h1_tag()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpStGC_STC8Q",
        "outputId": "579be8e1-2ffa-4347-95cd-8944c9e98d50"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h1 tag content: Example Domain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_image_links():\n",
        "    url = \"https://en.wikipedia.org/wiki/Peter_Jeffrey_(RAAF_officer)\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    images = soup.find_all(\"img\")\n",
        "    for img in images:\n",
        "        img_url = img.get(\"src\")\n",
        "        if img_url:\n",
        "            full_img_url = f\"https:{img_url}\"\n",
        "            print(full_img_url)\n",
        "scrape_image_links()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-yHm81ITH1m",
        "outputId": "e7e3f414-65f7-467e-f30e-ab0de06112ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https:/static/images/icons/wikipedia.png\n",
            "https:/static/images/mobile/copyright/wikipedia-wordmark-en.svg\n",
            "https:/static/images/mobile/copyright/wikipedia-tagline-en.svg\n",
            "https://upload.wikimedia.org/wikipedia/en/thumb/e/e7/Cscr-featured.svg/20px-Cscr-featured.svg.png\n",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/NlaJeffrey1942-43.jpg/220px-NlaJeffrey1942-43.jpg\n",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/008315JeffreyTurnbull1941.jpg/260px-008315JeffreyTurnbull1941.jpg\n",
            "https://upload.wikimedia.org/wikipedia/commons/e/ea/021807CameronJeffrey1941.jpg\n",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/AC0072JeffreyTruscottKittyhawks1942.jpg/280px-AC0072JeffreyTruscottKittyhawks1942.jpg\n",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/VIC1689Jeffrey1945.jpg/280px-VIC1689Jeffrey1945.jpg\n",
            "https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/30px-Commons-logo.svg.png\n",
            "https:https://login.wikimedia.org/wiki/Special:CentralAutoLogin/start?type=1x1\n",
            "https:/static/images/footer/wikimedia-button.svg\n",
            "https:/static/images/footer/poweredby_mediawiki.svg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def analyze_web_traffic():\n",
        "    url = \"https://www.data.gov/api/traffic\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        browser_traffic = {}\n",
        "        for record in data:\n",
        "            browser = record['browser']\n",
        "            count = record['count']\n",
        "            if browser in browser_traffic:\n",
        "                browser_traffic[browser] += count\n",
        "            else:\n",
        "                browser_traffic[browser] = count\n",
        "        for browser, count in browser_traffic.items():\n",
        "            print(f\"Browser: {browser}, Visits: {count}\")\n",
        "    else:\n",
        "        print(\"Failed to retrieve data.\")\n",
        "analyze_web_traffic()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKGIKnMGTOOq",
        "outputId": "11525f0c-55cd-4d5d-901c-a79c68e0e77c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve data.\n"
          ]
        }
      ]
    }
  ]
}